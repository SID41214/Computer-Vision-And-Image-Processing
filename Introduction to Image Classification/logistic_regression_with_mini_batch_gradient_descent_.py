# -*- coding: utf-8 -*-
"""Logistic Regression With Mini-Batch Gradient Descent .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qig5S_AWcs_9yESHgvMesKBHF-LlQPF1

# **Logistic Regression With Mini-Batch Gradient Descent**

# **Objective**
* Represent your data as a Dataset object
* Create a Logistic Regression Model using PyTorch
* Set a Criterion to calculate Loss
* Create a Data Loader and set the Batch Size
* Create an Optimizer to update Model Parameters and set Learning Rate
* Train a Model

# **Table of Contents**

To train a PyTorch Logistic Regression model using Mini-Batch Gradient Descent.

* Load Data
* Create the Model and Total Loss Function (Cost)
* Setting the Batch Size using a Data Loader
* Setting the Learning Rate
* Train the Model via Mini-Batch Gradient Descent

# Preparation
"""

!pip3 install torch torchvision torchaudio

# Import the libraries we need for this lab

# Allows us to use arrays to manipulate and store data
import numpy as np
# Used to graph data and loss curves
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
# PyTorch Library
import torch
# Used to help create the dataset and perform mini-batch
from torch.utils.data import Dataset, DataLoader
# PyTorch Neural Network
import torch.nn as nn

"""The class plot_error_surfaces is just to help you visualize the data space and the parameter space during training and has nothing to do with Pytorch."""

# Create class for plotting and the function for plotting

class plot_error_surfaces(object):

    # Construstor
    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):
        W = np.linspace(-w_range, w_range, n_samples)
        B = np.linspace(-b_range, b_range, n_samples)
        w, b = np.meshgrid(W, B)
        Z = np.zeros((30, 30))
        count1 = 0
        self.y = Y.numpy()
        self.x = X.numpy()
        for w1, b1 in zip(w, b):
            count2 = 0
            for w2, b2 in zip(w1, b1):
                yhat= 1 / (1 + np.exp(-1*(w2*self.x+b2)))
                Z[count1,count2]=-1*np.mean(self.y*np.log(yhat+1e-16) +(1-self.y)*np.log(1-yhat+1e-16))
                count2 += 1
            count1 += 1
        self.Z = Z
        self.w = w
        self.b = b
        self.W = []
        self.B = []
        self.LOSS = []
        self.n = 0
        if go == True:
            plt.figure()
            plt.figure(figsize=(7.5, 5))
            plt.axes(projection='3d').plot_surface(self.w, self.b, self.Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')
            plt.title('Loss Surface')
            plt.xlabel('w')
            plt.ylabel('b')
            plt.show()
            plt.figure()
            plt.title('Loss Surface Contour')
            plt.xlabel('w')
            plt.ylabel('b')
            plt.contour(self.w, self.b, self.Z)
            plt.show()

     # Setter
    def set_para_loss(self, model, loss):
        self.n = self.n + 1
        self.W.append(list(model.parameters())[0].item())
        self.B.append(list(model.parameters())[1].item())
        self.LOSS.append(loss)

    # Plot diagram
    def final_plot(self):
        ax = plt.axes(projection='3d')
        ax.plot_wireframe(self.w, self.b, self.Z)
        ax.scatter(self.W, self.B, self.LOSS, c='r', marker='x', s=200, alpha=1)
        plt.figure()
        plt.contour(self.w, self.b, self.Z)
        plt.scatter(self.W, self.B, c='r', marker='x')
        plt.xlabel('w')
        plt.ylabel('b')
        plt.show()

    # Plot diagram
    def plot_ps(self):
        plt.subplot(121)
        plt.ylim
        plt.plot(self.x[self.y==0], self.y[self.y==0], 'ro', label="training points")
        plt.plot(self.x[self.y==1], self.y[self.y==1]-1, 'o', label="training points")
        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label="estimated line")
        plt.xlabel('x')
        plt.ylabel('y')
        plt.ylim((-0.1, 2))
        plt.title('Data Space Iteration: ' + str(self.n))
        plt.show()
        plt.subplot(122)
        plt.contour(self.w, self.b, self.Z)
        plt.scatter(self.W, self.B, c='r', marker='x')
        plt.title('Loss Surface Contour Iteration' + str(self.n))
        plt.xlabel('w')
        plt.ylabel('b')

# Plot the diagram

def PlotStuff(X, Y, model, epoch, leg=True):

    plt.plot(X.numpy(), model(X).detach().numpy(), label=('epoch ' + str(epoch)))
    plt.plot(X.numpy(), Y.numpy(), 'r')
    if leg == True:
        plt.legend()
    else:
        pass

"""





Set the random seed:"""

# Setting the seed will allow us to control randomness and give us reproducibility
torch.manual_seed(0)

"""**Load Data**

The Dataset class represents a dataset. Your custom dataset should inherit Dataset which we imported above and override the following methods:

__len__ so that len(dataset) returns the size of the dataset.

__getitem__ to support the indexing such that dataset[i] can be used to get ith sample

Below we will create a sample dataset
"""

# Create the custom Data class which inherits Dataset
class Data(Dataset):

    # Constructor
    def __init__(self):
        # Create X values from -1 to 1 with step .1
        self.x = torch.arange(-1, 1, 0.1).view(-1, 1)
        # Create Y values all set to 0
        self.y = torch.zeros(self.x.shape[0], 1)
        # Set the X values above 0.2 to 1
        self.y[self.x[:, 0] > 0.2] = 1
        # Set the .len attribute because we need to override the __len__ method
        self.len = self.x.shape[0]

    # Getter that returns the data at the given index
    def __getitem__(self, index):
        return self.x[index], self.y[index]

    # Get length of the dataset
    def __len__(self):
        return self.len

"""Make Data object"""

# Create Data object
data_set = Data()

"""We can see the X values of the dataset"""

data_set.x

"""We can see the Y values of the dataset which correspond to the class of the X value"""

data_set.y

# We can get the length of the dataset

len(data_set)

# We can get the label  ùë¶
#   as well as the  ùë•
#   for the first sample

x,y = data_set[0]
print("x = {},  y = {}".format(x,y))

# We can get the label  ùë¶
#   as well as the  ùë•
#   for the second sample:

x,y = data_set[1]
print("x = {},  y = {}".format(x,y))

# We can see we can separate the one-dimensional dataset into two classes:

plt.plot(data_set.x[data_set.y==0], data_set.y[data_set.y==0], 'ro', label="y=0")
plt.plot(data_set.x[data_set.y==1], data_set.y[data_set.y==1]-1, 'o', label="y=1")
plt.xlabel('x')
plt.legend()

"""# Create the Model and Total Loss Function (Cost)

* For Logistic Regression typically we would not use PyTorch instead we would use Scikit-Learn as it is easier to use and set up. We are using PyTorch because it is good practice for deep learning. Scikit-Learn is typically used for Machine Learning while PyTorch is used for Deep Learning.

* We will create a custom class that defines the architecture of Logistic Regression using PyTorch. Logistic Regression has a single layer where the input is the number of features an X value of the dataset has (dimension of X) and there is a single output. The output of the layer is put into a sigmoid function which is a function between 0 and 1. The larger the output of the layer the closer it is to 1 and the smaller the output is the closer it is to 0. The sigmoid function will allow us to turn this output into a classification problem. If the output value is closer to 1 it is one class if it is closer to 0 it is in another.

* Sigmoid Function

![image.png](data:image/png;base64,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)
"""

# Create logistic_regression class that inherits nn.Module which is the base class for all neural networks
class logistic_regression(nn.Module):

    # Constructor
    def __init__(self, n_inputs):
        super(logistic_regression, self).__init__()
        # Single layer of Logistic Regression with number of inputs being n_inputs and there being 1 output
        self.linear = nn.Linear(n_inputs, 1)

    # Prediction
    def forward(self, x):
        # Using the input x value puts it through the single layer defined above then puts the output through the sigmoid function and returns the result
        yhat = torch.sigmoid(self.linear(x))
        return yhat

"""We can check the number of features an X value has, the size of the input, or the dimension of X"""

x,y = data_set[0]
len(x)

"""Create a logistic regression object or model, the input parameter is the number of dimensions."""

# Create the logistic_regression result

model = logistic_regression(1)

# We can make a prediction sigma  ùúé
#   this uses the forward function defined above

x = torch.tensor([-1.0])
sigma = model(x)
sigma

# We can also make a prediction using our data

x,y = data_set[2]
sigma = model(x)
sigma

"""Create a plot_error_surfaces object to visualize the data space and the learnable parameters space during training:

We can see on the Loss Surface graph, the loss value varying across w and b values with yellow being high loss and dark blue being low loss which is what we want

On the Loss Surface Contour graph we can see a top-down view of the Loss Surface graph
"""

# Create the plot_error_surfaces object

# 15 is the range of w
# 13 is the range of b
# data_set[:][0] are all the X values
# data_set[:][1] are all the Y values

get_surface = plot_error_surfaces(15, 13, data_set[:][0], data_set[:][1])

"""We define a criterion using Binary Cross Entropy Loss. This will measure the difference/loss between the prediction and actual value.

"""

criterion = nn.BCELoss()

# We have our samples:

x, y = data_set[0]
print("x = {},  y = {}".format(x,y))

# We can make a prediction using the model:

sigma = model(x)
sigma

# We can calculate the loss

loss = criterion(sigma, y)
loss

"""# Setting the Batch Size using a Data Loader

You have to use data loader in PyTorch that will output a batch of data, the input is the dataset and batch_size
"""

batch_size=10

trainloader = DataLoader(dataset = data_set, batch_size = 10)
dataset_iter = iter(trainloader)
X,y=next(dataset_iter )


# We can see here that 10 values the same as our batch size
X

"""# Setting the Learning Rate

We can set the learning rate by setting it as a parameter in the optimizer along with the parameters of the logistic regression model we are training. The job of the optimizer, torch.optim.SGD, is to use the loss generated by the criterion to update the model parameters according to the learning rate. SGD stands for Stochastic Gradient Descent which typically means that the batch size is set to 1, but the data loader we set up above has turned this into Mini-Batch Gradient Descent.
"""

learning_rate = 0.1

optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)

"""# Train the Model via Mini-Batch Gradient Descent

We are going to train the model using various Batch Sizes and Learning Rates.

# Mini-Batch Gradient Descent

In this case, we will set the batch size of the data loader to 5 and the number of epochs to 250.

First, we must recreate the get_surface object again so that for each example we get a Loss Surface for that model only.
"""

get_surface = plot_error_surfaces(15, 13, data_set[:][0], data_set[:][1], 30)

"""**Train the Model**"""

# First we create an instance of the model we want to train
model = logistic_regression(1)
# We create a criterion which will measure loss
criterion = nn.BCELoss()
# We create a data loader with the dataset and specified batch size of 5
trainloader = DataLoader(dataset = data_set, batch_size = 5)
# We create an optimizer with the model parameters and learning rate
optimizer = torch.optim.SGD(model.parameters(), lr = .01)
# Then we set the number of epochs which is the total number of times we will train on the entire training dataset
epochs=500
# This will store the loss over iterations so we can plot it at the end
loss_values = []

# Loop will execute for number of epochs
for epoch in range(epochs):
    # For each batch in the training data
    for x, y in trainloader:
        # Make our predictions from the X values
        yhat = model(x)
        # Measure the loss between our prediction and actual Y values
        loss = criterion(yhat, y)
        # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset
        optimizer.zero_grad()
        # Calculates the gradient value with respect to each weight and bias
        loss.backward()
        # Updates the weight and bias according to calculated gradient value
        optimizer.step()
        # Set the parameters for the loss surface contour graphs
        get_surface.set_para_loss(model, loss.tolist())
        # Saves the loss of the iteration
        loss_values.append(loss)
    # Want to print the Data Space for the current iteration every 20 epochs
    if epoch % 20 == 0:
        get_surface.plot_ps()

"""* Notice in this example the due to the high learning rate the Loss Surface Contour graph has increased movement over the previous example and also moves in multiple directions due to the minimum being overshot.

* We can see the final values of the weight and bias. This weight and bias correspond to the orange line in the Data Space graph and the final spot of the X in the Loss Surface Contour graph.
"""

w = model.state_dict()['linear.weight'].data[0]
b = model.state_dict()['linear.bias'].data[0]
print("w = ", w, "b = ", b)

"""Now we can get the accuracy of the training data"""

# Getting the predictions
yhat = model(data_set.x)
# Rounding the prediction to the nearedt integer 0 or 1 representing the classes
yhat = torch.round(yhat)
# Counter to keep track of correct predictions
correct = 0
# Goes through each prediction and actual y value
for prediction, actual in zip(yhat, data_set.y):
    # Compares if the prediction and actualy y value are the same
    if (prediction == actual):
        # Adds to counter if prediction is correct
        correct+=1
# Outputs the accuracy by dividing the correct predictions by the length of the dataset
print("Accuracy: ", correct/len(data_set)*100, "%")

"""

Finally, we plot the Cost vs Iteration graph, although it is erratic it is downward sloping.
"""

LOSS_BGD1=[]
for i in loss_values:
    LOSS_BGD1.append(i.item())


plt.plot(LOSS_BGD1)
plt.xlabel("Iteration")
plt.ylabel("Cost")

"""Using the following code train the model using a learning rate of .01, 120 epochs, and batch_size of 1"""

# First we create an instance of the model we want to train
# model = logistic_regression(1)
# # We create a criterion which will measure loss
# criterion = nn.BCELoss()
# # We create a data loader with the dataset and specified batch size of 1
# trainloader = DataLoader(dataset = data_set, batch_size = "SET_BATCH_SIZE")
# # We create an optimizer with the model parameters and learning rate
# optimizer = torch.optim.SGD(model.parameters(), lr = "SET_LEARNING_RATE")
# # Then we set the number of epochs which is the total number of times we will train on the entire training dataset
# epochs= "SET_NUMBER_OF_EPOCHS"
# # This will store the loss over iterations so we can plot it at the end
# loss_values = []

# # Loop will execute for number of epochs
# for epoch in range(epochs):
#     # For each batch in the training data
#     for x, y in trainloader:
#         # Make our predictions from the X values
#         yhat = model(x)
#         # Measure the loss between our prediction and actual Y values
#         loss = criterion(yhat, y)
#         # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset
#         optimizer.zero_grad()
#         # Calculates the gradient value with respect to each weight and bias
#         loss.backward()
#         # Updates the weight and bias according to calculated gradient value
#         optimizer.step()
#         # Set the parameters for the loss surface contour graphs
#         get_surface.set_para_loss(model, loss.tolist())
#         # Saves the loss of the iteration
#         loss_values.append(loss)
#     # Want to print the Data Space for the current iteration every 20 epochs
#     if epoch % 20 == 0:
#         get_surface.plot_ps()

# First we create an instance of the model we want to train
model = logistic_regression(1)
# We create a criterion which will measure loss
criterion = nn.BCELoss()
# We create a data loader with the dataset and specified batch size of 1
# The batch size is changed to an integer value
trainloader = DataLoader(dataset = data_set, batch_size = 1)
# We create an optimizer with the model parameters and learning rate
# The learning rate is changed to a float value
optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)
# Then we set the number of epochs which is the total number of times we will train on the entire training dataset
# The number of epochs is changed to an integer value
epochs = 500
# This will store the loss over iterations so we can plot it at the end
loss_values = []

# ... (rest of the code remains the same)

"""We can see the final values of the weight and bias. This weight and bias correspond to the orange line in the Data Space graph and the final spot of the X in the Loss Surface Contour graph."""

w = model.state_dict()['linear.weight'].data[0]
b = model.state_dict()['linear.bias'].data[0]
print("w = ", w, "b = ", b)

# Getting the predictions
yhat = model(data_set.x)
# Rounding the prediction to the nearedt integer 0 or 1 representing the classes
yhat = torch.round(yhat)
# Counter to keep track of correct predictions
correct = 0
# Goes through each prediction and actual y value
for prediction, actual in zip(yhat, data_set.y):
    # Compares if the prediction and actualy y value are the same
    if (prediction == actual):
        # Adds to counter if prediction is correct
        correct+=1
# Outputs the accuracy by dividing the correct predictions by the length of the dataset
print("Accuracy: ", correct/len(data_set)*100, "%")

"""Finally, we plot the Cost vs Iteration graph, although it is erratic it is downward sloping."""

LOSS_BGD1=[]
for i in loss_values:
    LOSS_BGD1.append(i.item())


plt.plot(LOSS_BGD1)
plt.xlabel("Iteration")
plt.ylabel("Cost")